from .Posterior import Posterior
from scipy.stats import norm
import numpy as np


class Uniform(Posterior):

    def __init__(self, paramDict, i=0):
        """
        :param paramDict: <dict> of necessary parameters to initialize the posterior distribution
        :param i: <int> if > 0 then means there are parameters for multile posteriors in the dictionary

        Calling this a 'posterior' but since our real objective is to estimate the support of the Band distribution
            then the real goal is to estimate the lower bound of the support of the band distribution (assuming known
            scale parameter), so the implementation is based on finding this lowerbound i.e. x_max - scale

        Note: Will not be perfect because our observations are actually estimates of bin means, and not true means
        still need to figure out this "belief propagation" issue
        """
        # Setting initial parameters
        if isinstance(paramDict["loc"],float):
            self._min = paramDict["loc"]
            self._max = paramDict["loc"] + paramDict["scale"]
            self._scale = paramDict["scale"]
        else:
            self._min = paramDict["loc"][i]
            self._max = paramDict["loc"] + paramDict["scale"][i]
            self._scale = paramDict["scale"][i]
        self._mean = (self._max + self._min) / 2


        # Setting prior parameters that'll become posterior parameters
        self.min = self._min
        self.max = self._max
        self.scale = self._scale
        self.mean = self._mean

        self._nb_data = 0  # number of samples!
        self._sum_data = 0.0  # sum of samples!

        self.obs_min = np.inf
        self.obs_max = -np.inf
        self.likelihoodParams = {
                "loc": self._min,
                "scale": self._scale,
                "max": self._max
        }

    def __str__(self):
        return "Uniform(min = {:.3g},max = {:.3g}, scale =  {:.3g}".format(self.min, self.max, self.scale)

    def getLikelihood(self):
        return self.likelihoodParams

    def reset(self, loc=None,scale=None):
        r""" Reset the for parameters :eta and tau, as when creating a new NormalGamma posterior."""
        if loc is None:
            self.min = self._min
        if scale is None:
            self.scale = self._scale

    def sample(self):
        # https://en.wikipedia.org/wiki/Normal-gamma_distribution
        # Random variable X|T ~ N(eta, 1/(gam*T) where T|(alpha, beta) ~ Gamma(alpha, beta)
        # Then the joint distribtuion (X,T) ~ NormalGamma(eta, gam, alpha, beta)
        # Sample first from gamma(alpha, beta) to get T
        # Sample from normal(eta, 1/(lgam*T)) to get X
        return np.random.uniform(low = self.min, high = self.max)

    def sample_k(self, k=100):
        for ii in range(k):
            X[ii] = self.sample()
        return X

    def update(self, obs):  # Remember we are updating out posterior P(a|obs)
        if self.obs_max < obs: # If our recorded max is less than the observed
            self.obs_max = obs
            self.max = obs # Update the max

        self.min = self.max-self.scale # Assuming scale is actually known
        self.mean = (self.max + self.min) / 2
        # Since we are sampling from the likelihood distribution, its support
        # cannot be lower than that of the actual
        # (See Parameter Estimation###Uniform Likelihood distribution)
        self.likelihoodParams["loc"] = self.min
        self.likelihoodParams["mean"] = self.mean
        self.likelihoodParams["max"] = self.max





