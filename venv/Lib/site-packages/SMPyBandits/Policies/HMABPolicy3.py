

from .HMABBasePolicy import HMABBasePolicy
from .Posterior import NormalGamma
from numpy.random import normal as normalvariate
import numpy as np

class HMABPolicy3(HMABBasePolicy):
    """
    Band selection is random and so is bin
    Used to test the updating the of the Posterior - Goal is not to minimize regret, but to estimate the true distribution of X_i
    """
    # def __init__(self):
    #     super(HMABPolicy1, self).__init__()


    def choice(self, verbose = True): # This is where I finally implement the algorithm

        def chooseBand():
            if verbose:
                print()
                print("*" * 20)
                print(f"Time = {self.t}")
                print("*" * 20)
            chosen = None
            BandSamp = np.zeros(self.nbBands)
            mu = np.zeros(self.nbBands)
            std = np.zeros(self.nbBands)

            # We need to sample from the likelihood, whose parameters come from the posterior
            for Band in range(self.nbBands):
                mu[Band]  = self.likelihoodParams[Band][0]
                std[Band] = np.sqrt(1/self.likelihoodParams[Band][1])
                BandSamp[Band] = normalvariate(loc = mu[Band], scale = std[Band])



            #chosen = np.argmax(BandSamp)
            chosen = np.random.randint(0,self.nbBands)
            if verbose:
                for Band in range(self.nbBands):
                    print(f"""The POSTERIOR for Band ({Band}) is ~ {self.posteriorBand[Band].__str__()}""")
                    print(f"""The LIKELIHOOD L()for Band ({Band}) is ~ Normal(mu = {mu[Band]}, var = {std[Band]**2})""")
                    print(f"""The sample from L() for Band ({Band}) was {BandSamp[Band]} """)
                print("*" * 20)
                print(f"""The chosen Band is ({chosen}) with sample = {BandSamp[chosen]}""")

            return chosen

        def chooseBin(Band): # Uniformly Sample Bins
            self.computeBandArmIndex(Band)
            best_ind = np.argmax(self.indexes)
            rand_ind = np.random.randint(0,self.nbBins)
            if verbose:
                print("*"*20)
                print(f"Choosing a Bin within Band ({Band})")
                #ind_formatted = (f"{ind:0.3f}" for ind in self.indexes)
                print(f"The bin indices in order are: {np.array_str(self.indexes, precision=3)}")
                print(f"""The chosen random Bin is ({rand_ind}) with index = {self.indexes[best_ind]}""")
            return rand_ind

        Band = chooseBand()
        #Bin = None
        Bin = chooseBin(Band)

        return (Band, Bin)

    def getReward(self, choice, reward): #Need to update posteriors now
        """ Give a reward: increase t, pulls, and update cumulated sum of rewards for that arm (normalized in [0, 1])."""
        print("*"*20)
        print(f"Updating the Posterior for Band {choice[0]}")
        print(f"Based on Bin {choice[1]} sampled with received reward = {reward:0.3f}")
        Band = choice[0]
        Bin = choice[1]
        self.t += 1
        self.pulls[Band, Bin] += 1
        self.rewards[Band, Bin] += reward
        # Update estimated expected reward for the bin
        self.lam_est[Band, Bin] = self.rewards[Band, Bin]/self.pulls[Band, Bin] # This is our observation that we will used to update the posterior for the Band
        # self.Mu_est[Band] = np.mean(self.lam_est[Band,:])
        print(f"Old posterior for Band ({Band}): {self.posteriorBand[Band].__str__()}")
        self.posteriorBand[Band].update(self.lam_est[Band, Bin]) # This updates the posterior
        print(f"New posterior for Band ({Band}): {self.posteriorBand[Band].__str__()}")
        # Now we need to update the likelihood:
        print(f"Old likelihood for Band ({Band}): N({self.likelihoodParams[Band][0]}, {1/self.likelihoodParams[Band][1]}) ")
        self.likelihoodParams[Band] = self.posteriorBand[Band].mean()
        print(f"New likelihood for Band ({Band}): N({self.likelihoodParams[Band][0]}, {1/self.likelihoodParams[Band][1]}) ")
        print("*"*20)
        test = 1