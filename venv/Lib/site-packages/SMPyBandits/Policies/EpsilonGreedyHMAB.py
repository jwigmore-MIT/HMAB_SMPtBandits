
from .HMABPolicy import HMABPolicy
from numpy.random import choice as npchoice
from numpy.random import randint
import numpy as np
from numpy.random import default_rng
rng = default_rng()
from .Posterior.Uniform import Uniform
from .Posterior.NormalGamma import *


class EpsilonGreedyHMAB(HMABPolicy):
    """ Implementation of Epsilon-Greedy assuming Z_i~ Normal(mu_i, sigma^2) where sigma is the same for all Bands"""

    def __init__(self, nbBands, nbBins, posterior, priorParams, verbose=True, epsilon = 0.5):
        super().__init__(nbBands, nbBins, posterior, priorParams, verbose)
        self.epsilon = epsilon
        self.bestBandLoc = -np.inf

        self.bestBand  = rng.choice(self.getBestBand())


    def choice(self):
        def chooseBand():
            r = rng.binomial(1, self.epsilon)

            if r ==  1:
                if self.verbose:
                    print(f"r = {r} - Choosing best band")
                Band = self.bestBand
            else:
                if self.verbose:
                    print(f"r = {r} - Choosing random band")
                Band = rng.integers(0, self.nbBands)
            return Band, r

        def chooseBin(Band, r):
        #If it was an exploitation step (r==1), run UCB1 on the bins within the Band
            if r == 1:
                self.computeBandArmIndex(Band)
                self.computeBandArmIndex(Band)
                best_ind = np.argmax(self.indexes)
                if self.verbose:
                    print("*" * 20)
                    print(f"Choosing a Bin within Band ({Band})")
                    # ind_formatted = (f"{ind:0.3f}" for ind in self.indexes)
                    print(f"The bin indices in order are: {np.array_str(self.indexes, precision=3)}")
                    print(f"""The chosen Bin is ({best_ind}) with index = {self.indexes[best_ind]}""")
                Bin = best_ind
        # If it was an exploration step (r==0), select a Bin uniformly at random from the Bin
            Bin = rng.integers(0, self.nbBins)
            return Bin
        Band, r = chooseBand()
        Bin = chooseBin(Band, r)
        choice = self.getArm(Band, Bin)
        return choice


    def getBestBand(self):
        bestBands = list()
        i = 0
        for Z_i in self.likelihoodParams:  # Each Z_i is a dictionary with location and scale parameter
            if Z_i["loc"] >= self.bestBandLoc:
                bestBands.append(i)
                self.bestBandLoc = Z_i["loc"]
            i = i+1
        return bestBands



    def printPolicyInfo(self):
        self.sortArms()
        np.set_printoptions(precision=2)
        print("*" * 20)
        print(f"### POLICY INFORMATION")
        print(f"Policy: {type(self).__name__}")
        for Band in range(self.nbBands):
            print(f"#### Band ({Band})")
            posterior = self.posteriorBand[Band]
            posterior.printAllParams()
            print(f"Estimated bin reward means: {self.lam_estBB[Band, :]}")
            print("*" * 20)

        estBestArm0 = self.getBB(self.estBestArms[0])
        estBestvalue0 = self.estBestValues[0]
        estBestArm1 = self.getBB(self.estBestArms[1])
        estBestvalue1 = self.estBestValues[1]
        gap = estBestvalue0 - estBestvalue1
        print(f"### Estimation Gap")
        print(f"Estimated 1st best Band/Bin = {estBestArm0} w/ value = {estBestvalue0}")
        print(f"Estimated 2nd best Band/Bin = {estBestArm1} w/ value = {estBestvalue1}")
        print(f"Gap = {gap}")
        print()
        self.printStageTimeline()



