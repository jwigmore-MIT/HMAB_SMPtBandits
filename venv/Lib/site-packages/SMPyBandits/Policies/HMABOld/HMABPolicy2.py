

from SMPyBandits.Policies.HMABBasePolicy import HMABBasePolicy
from SMPyBandits.Policies.Posterior import NormalGamma
from numpy.random import normal as normalvariate
import numpy as np

class HMABPolicy2(HMABBasePolicy):
    """
    Instead of sampling the bin based off UCB, it chooses a bin uniformly at random from the Band
    Band selection remains the same
    """
    # def __init__(self):
    #     super(HMABPolicy1, self).__init__()


    def choice(self, verbose = True): # This is where I finally implement the algorithm

        def chooseBand():
            if verbose:
                print()
                print("*" * 20)
                print(f"Time = {self.t}")
                print("*" * 20)
            chosen = None
            BandSamp = np.zeros(self.nbBands)
            mu = np.zeros(self.nbBands)
            std = np.zeros(self.nbBands)

            # We need to sample from the likelihood, whose parameters come from the posterior
            for Band in range(self.nbBands):
                mu[Band]  = self.likelihoodParams[Band][0]
                std[Band] = np.sqrt(1/self.likelihoodParams[Band][1])
                BandSamp[Band] = normalvariate(loc = mu[Band], scale = std[Band])



            chosen = np.argmax(BandSamp)
            if verbose:
                for Band in range(self.nbBands):
                    print(f"""The POSTERIOR for Band ({Band}) is ~ {self.posteriorBand[Band].__str__()}""")
                    print(f"""The LIKELIHOOD L()for Band ({Band}) is ~ Normal(mu = {mu[Band]}, var = {std[Band]**2})""")
                    print(f"""The sample from L() for Band ({Band}) was {BandSamp[Band]} """)
                print("*" * 20)
                print(f"""The chosen Band is ({chosen}) with sample = {BandSamp[chosen]}""")

            return chosen

        def chooseBin(Band): # Uniformly Sample Bins
            self.computeBandArmIndex(Band)
            best_ind = np.argmax(self.indexes)
            rand_ind = np.random.randint(0,self.nbBins)
            if verbose:
                print("*"*20)
                print(f"Choosing a Bin within Band ({Band})")
                #ind_formatted = (f"{ind:0.3f}" for ind in self.indexes)
                print(f"The bin indices in order are: {np.array_str(self.indexes, precision=3)}")
                print(f"""The chosen random Bin is ({rand_ind}) with index = {self.indexes[best_ind]}""")
            return rand_ind

        Band = chooseBand()
        #Bin = None
        Bin = chooseBin(Band)
        choice = self.getArm(Band,Bin)
        return choice

    def getReward(self, choice, reward, verbose=True):  # Need to update posteriors now
        """ Give a reward: increase t, pulls, and update cumulated sum of rewards for that arm (normalized in [0, 1])."""

        (Band, Bin) = self.getBB(choice)
        self.t += 1
        self.updatePulls(Band, Bin)
        self.updateReward(Band, Bin, reward, lam_est= True) #update reward and expected reward for bin
        self.posteriorBand[Band].update(self.lam_estBB[Band, Bin])  # This updates the posterior
        # Now we need to update the likelihood:
        self.likelihoodParams[Band] = self.posteriorBand[Band].mean()
        if verbose:
            print(
                f"New likelihood for Band ({Band}): N({self.likelihoodParams[Band][0]}, {1 / self.likelihoodParams[Band][1]}) ")
            print("*" * 20)
            print("*" * 20)
            print(f"Updating the Posterior for Band {Band}")
            print(f"Based on Bin {Bin} sampled with received reward = {reward:0.3f}")
            print(f"Old posterior for Band ({Band}): {self.posteriorBand[Band].__str__()}")
            print(f"New posterior for Band ({Band}): {self.posteriorBand[Band].__str__()}")
            print(
                f"Old likelihood for Band ({Band}): N({self.likelihoodParams[Band][0]}, {1 / self.likelihoodParams[Band][1]}) ")
        test = 1